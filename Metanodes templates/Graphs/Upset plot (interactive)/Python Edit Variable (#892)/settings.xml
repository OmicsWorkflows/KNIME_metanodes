<?xml version="1.0" encoding="UTF-8"?>
<config xmlns="http://www.knime.org/2008/09/XMLConfig" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.knime.org/2008/09/XMLConfig http://www.knime.org/XMLConfig_2008_09.xsd" key="settings.xml">
<entry key="node_file" type="xstring" value="settings.xml"/>
<config key="flow_stack"/>
<config key="internal_node_subsettings">
<entry key="memory_policy" type="xstring" value="CacheSmallInMemory"/>
</config>
<config key="model">
<entry key="sourceCode" type="xstring" value="# Create JSON file for UpSet%%00010%%00010import json%%00010import os.path%%00010from os import chdir, remove%%00010import glob%%00010%%00010##########################################################################%%00010%%00010# Parameter inputs%%00010csvFileRelPath = flow_variables['csv_file_path']%%00010# string, integer, float, binary%%00010columnCounts = [flow_variables['Number Columns_metadata-string'], flow_variables['Number Columns_metadata-integer'], flow_variables['Number Columns_metadata-float'], flow_variables['Number Columns']]%%00010datasetName = &quot;knime_dataset&quot;%%00010upsetPath = flow_variables['upset_path']%%00010# add only this dataset? 1 = yes; 0 = no%%00010addOnlyThisDataset = True%%00010# remove the dataset? 1 = yes; 0 = no%%00010removeActualDatasetAfterOpen = flow_variables['removeActualDatasetAfterOpen']%%00010# older version%%00010#addOnlyThisDataset = True%%00010#removeActualDatasetAfterOpen = True%%00010##########################################################################%%00010%%00010# Csv parameters%%00010default_index = 1%%00009# default ... 0; for knime ... 1 (on index 0 is default rowID)%%00010separator = &quot;\t&quot;%%00009# &quot;,&quot; or &quot;;&quot; or &quot;\t&quot;%%00010%%00010# Other parameters%%00010datasetsFileName = &quot;datasets.json&quot;%%00010timeToWait = 30%%00009%%00009# time to wait before removing actual dataset files (csv, json)%%00010%%00010# Computed constants from parameters%%00010knime_data_folder = os.path.dirname(csvFileRelPath)%%00010name = os.path.splitext(os.path.basename(csvFileRelPath))[0]%%00010csvFileAbsPath = os.path.join(upsetPath, csvFileRelPath)%%00010jsonFileName = name + &quot;.json&quot;%%00010jsonFileRelPath = os.path.join(knime_data_folder, jsonFileName)%%00010jsonFileAbsPath = os.path.join(upsetPath, jsonFileRelPath)%%00010upsetAppPath = os.path.join(upsetPath, &quot;index.html&quot;)%%00010%%00010%%00010%%00010def re_create_datasets_file(only_actual):%%00010%%00009# Re-Create datasets.json%%00010%%00009datasets_list = []%%00010%%00010%%00009if only_actual == 1:%%00010%%00009%%00009datasets_list.append(jsonFileRelPath)%%00010%%00010%%00009else:%%00010%%00009%%00009chdir(upsetPath)%%00010%%00009%%00009glob_path = os.path.join(knime_data_folder, &quot;*.json&quot;)%%00010%%00009%%00009json_files_list = glob.glob(glob_path)%%00010%%00009%%00009json_files_list.sort()%%00010%%00010%%00009%%00009if (jsonFileRelPath in json_files_list):%%00010%%00009%%00009%%00009datasets_list.append(jsonFileRelPath)%%00010%%00009%%00009%%00010%%00009%%00009for json_file in json_files_list:%%00010%%00009%%00009%%00009if json_file != jsonFileRelPath:%%00010%%00009%%00009%%00009%%00009datasets_list.append(json_file)%%00010%%00010%%00010%%00009datasetsPath = os.path.join(upsetPath, datasetsFileName)%%00010%%00009with open(datasetsPath, &quot;w&quot;) as fp2:%%00010%%00009%%00009json.dump(datasets_list, fp2)%%00010%%00010%%00010%%00010%%00010%%00010#if __name__ == '__main__':%%00010%%00010if True:%%00010%%00010%%00009# JSON Data%%00010%%00009data = {%%00010%%00009%%00009&quot;file&quot;: csvFileRelPath,%%00010%%00009%%00009&quot;name&quot;: datasetName,%%00010%%00009%%00009&quot;header&quot;: 0,%%00010%%00009%%00009&quot;separator&quot;: separator,%%00010%%00009%%00009&quot;skip&quot;: 0,%%00010%%00009%%00009&quot;author&quot;: &quot;UpSet plot (interactive) metanode&quot;,%%00010%%00009%%00009&quot;description&quot;: &quot;&quot;,%%00010%%00009%%00009&quot;source&quot;: &quot;&quot;,%%00010%%00009%%00009&quot;meta&quot;: []%%00010%%00009}%%00010%%00010%%00010%%00009index = default_index%%00010%%00009# Meta -&gt; ID + strings%%00010%%00009for x in range(columnCounts[0]):%%00010%%00009%%00009if (index == default_index):%%00010%%00009%%00009%%00009meta_type = &quot;id&quot;%%00010%%00009%%00009else:%%00010%%00009%%00009%%00009meta_type = &quot;string&quot;%%00010%%00009%%00009data[&quot;meta&quot;].append({ &quot;type&quot;: meta_type, &quot;index&quot;: index})%%00010%%00009%%00009index = index+1%%00010%%00010%%00009# Meta -&gt; Integers%%00010%%00009for x in range(columnCounts[1]):%%00010%%00009%%00009data[&quot;meta&quot;].append({ &quot;type&quot;: &quot;integer&quot;, &quot;index&quot;: index})%%00010%%00009%%00009index = index+1%%00010%%00010%%00009# Meta -&gt; Floats%%00010%%00009for x in range(columnCounts[2]):%%00010%%00009%%00009data[&quot;meta&quot;].append({ &quot;type&quot;: &quot;float&quot;, &quot;index&quot;: index})%%00010%%00009%%00009index = index+1%%00010%%00010%%00009# Sets%%00010%%00009binary_set_start = default_index + columnCounts[0] + columnCounts[1] + columnCounts[2]%%00010%%00009binary_set_end = binary_set_start + columnCounts[3] - 1%%00010%%00009data[&quot;sets&quot;] = [%%00010%%00009%%00009{ &quot;format&quot;: &quot;binary&quot;, &quot;start&quot;: binary_set_start, &quot;end&quot;: binary_set_end}%%00010%%00009]%%00010%%00010%%00010%%00010%%00010%%00009# Create JSON file%%00010%%00009with open(jsonFileAbsPath, &quot;w&quot;) as fp:%%00010%%00009%%00009json.dump(data, fp)%%00010%%00010%%00010%%00009# Re-create datasets.json%%00010%%00009re_create_datasets_file(addOnlyThisDataset)%%00010%%00010%%00010%%00010%%00009# Open UpSet in Firefox%%00010%%00009import webbrowser%%00010%%00009url = &quot;file://&quot; + upsetAppPath%%00010%%00009#webbrowser.get(&quot;firefox&quot;).open_new(url)%%00010%%00009webbrowser.open(url)%%00010%%00010%%00010%%00010%%00009# Remove actual csv and json file%%00010%%00009if removeActualDatasetAfterOpen == 1:%%00010%%00009%%00009print(&quot;Sleep before removing actual dataset files for &quot; + str(timeToWait) + &quot;s&quot;)%%00010%%00009%%00009import time%%00010%%00009%%00009for x in range(timeToWait):%%00010%%00009%%00009%%00009time.sleep(1)%%00010%%00009%%00009%%00009print(&quot;.&quot;, end=&quot;&quot;)%%00010%%00009%%00009print()%%00010%%00009%%00009if os.path.exists(jsonFileAbsPath):%%00010%%00009%%00009%%00009remove(jsonFileAbsPath)%%00010%%00009%%00009if os.path.exists(csvFileAbsPath):%%00010%%00009%%00009%%00009remove(csvFileAbsPath)%%00010%%00009%%00009re_create_datasets_file(False)%%00010%%00010%%00010%%00010%%00009# End%%00010%%00009#print(&quot;True&quot;)"/>
<entry key="rowLimit" type="xint" value="1000"/>
<entry key="pythonVersionOption" type="xstring" value="PYTHON3"/>
<entry key="convertMissingToPython" type="xboolean" value="false"/>
<entry key="convertMissingFromPython" type="xboolean" value="false"/>
<entry key="sentinelOption" type="xstring" value="MIN_VAL"/>
<entry key="sentinelValue" type="xint" value="0"/>
<entry key="chunkSize" type="xint" value="500000"/>
</config>
<config key="nodeAnnotation">
<entry key="text" type="xstring" value="writes out the dataset %%00010json file, modifies datasets.json file%%00010and opens the browser for you with %%00010UpSet application"/>
<entry key="bgcolor" type="xint" value="16777215"/>
<entry key="x-coordinate" type="xint" value="1396"/>
<entry key="y-coordinate" type="xint" value="959"/>
<entry key="width" type="xint" value="208"/>
<entry key="height" type="xint" value="68"/>
<entry key="alignment" type="xstring" value="CENTER"/>
<entry key="borderSize" type="xint" value="0"/>
<entry key="borderColor" type="xint" value="16777215"/>
<entry key="defFontSize" type="xint" value="10"/>
<entry key="annotation-version" type="xint" value="20151123"/>
<config key="styles"/>
</config>
<entry key="customDescription" type="xstring" isnull="true" value=""/>
<entry key="state" type="xstring" value="IDLE"/>
<entry key="factory" type="xstring" value="org.knime.python2.nodes.variables.Python2VariablesNodeFactory"/>
<entry key="node-name" type="xstring" value="Python Edit Variable"/>
<entry key="node-bundle-name" type="xstring" value="KNIME Python nodes"/>
<entry key="node-bundle-symbolic-name" type="xstring" value="org.knime.python2.nodes"/>
<entry key="node-bundle-vendor" type="xstring" value="KNIME AG, Zurich, Switzerland"/>
<entry key="node-bundle-version" type="xstring" value="3.6.1.v201808311614"/>
<entry key="node-feature-name" type="xstring" value="KNIME Python Integration"/>
<entry key="node-feature-symbolic-name" type="xstring" value="org.knime.features.python2.feature.group"/>
<entry key="node-feature-vendor" type="xstring" value="KNIME AG, Zurich, Switzerland"/>
<entry key="node-feature-version" type="xstring" value="3.6.1.v201808311614"/>
<config key="factory_settings"/>
<entry key="name" type="xstring" value="Python Edit Variable"/>
<entry key="hasContent" type="xboolean" value="false"/>
<entry key="isInactive" type="xboolean" value="false"/>
<config key="ports">
<config key="port_1">
<entry key="index" type="xint" value="1"/>
<entry key="port_dir_location" type="xstring" isnull="true" value=""/>
</config>
</config>
<config key="filestores">
<entry key="file_store_location" type="xstring" isnull="true" value=""/>
<entry key="file_store_id" type="xstring" isnull="true" value=""/>
</config>
</config>
